{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA DOWNLOAD\n",
    "To start this project, you need an addition data file.\n",
    "\n",
    "First you should download data from:\n",
    "https://pan.baidu.com/s/1KFui9zZKjRqzFkCJH5nenw\n",
    "    \n",
    "Then unzip it,create a data dir, and put it in data directory\n",
    "\n",
    "## After you do all that , the following file should be found:\n",
    "\n",
    "```python\n",
    "'data/segmented_train_seg_by_word.txt' \n",
    "```\n",
    "\n",
    "And that means you are good to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000000 data/segmented_train_seg_by_word.txt\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l data/segmented_train_seg_by_word.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import ProgressBar\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100.00 % [==================================================>] 10000000/10000000 \t used:78s eta:0 s"
     ]
    }
   ],
   "source": [
    "enline = None\n",
    "chline = None\n",
    "\n",
    "sentlength = 5\n",
    "\n",
    "enlines = []\n",
    "chlines = []\n",
    "pb = ProgressBar(worksum=10000000)\n",
    "pb.startjob()\n",
    "num = 0\n",
    "with open('data/segmented_train_seg_by_word.txt') as fhdl:\n",
    "    for line in fhdl:\n",
    "        num += 1\n",
    "        if num % 2 == 1:\n",
    "            enline = line\n",
    "            continue\n",
    "        else:\n",
    "            chline = line\n",
    "        \n",
    "        enlinesp = [i.lower() for i in enline.strip(\"\\n\").split()]\n",
    "        chlinesp = [i for i in chline.strip(\"\\n\").replace(' ','')]\n",
    "        if len(enlinesp) <= sentlength and len(chlinesp) <= sentlength:\n",
    "            enlines.append(enlinesp)\n",
    "            chlines.append(chlinesp)\n",
    "        if (num // 2) % 1000 == 0:\n",
    "            pb.complete(1000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['deuces', 'the', 'winner', '.'],\n",
       " ['a', 'couple', 'of', 'what', '?'],\n",
       " ['a', 'pair', 'of', 'wives', '?'],\n",
       " ['husband', 'and', 'wife', '.'],\n",
       " ['couple', '.'],\n",
       " ['nice', 'couple', '.'],\n",
       " ['two', 'lovers', '.'],\n",
       " ['a', 'couple', 'getting', 'married', '.'],\n",
       " ['couple', 'of', 'newbies', '?'],\n",
       " ['a', 'couple', 'of', 'gunslingers', '.']]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enlines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['一', '对', '二', '胜', '。'],\n",
       " ['一', '对', '什', '么', '？'],\n",
       " ['一', '对', '太', '太', '？'],\n",
       " ['一', '对', '夫', '妇', '。'],\n",
       " ['一', '对', '夫', '妻', '。'],\n",
       " ['一', '对', '好', '人', '。'],\n",
       " ['一', '对', '情', '人', '。'],\n",
       " ['一', '对', '新', '人', '。'],\n",
       " ['一', '对', '新', '手', '？'],\n",
       " ['一', '对', '枪', '手', '。']]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chlines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103912, 103912)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chlines),len(enlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enwords = []\n",
    "chwords = []\n",
    "for sent in enlines:\n",
    "    for enword in sent:\n",
    "        enwords.append(enword)\n",
    "        \n",
    "for sent in chlines:\n",
    "    for chword in sent:\n",
    "        chwords.append(chword)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 49461),\n",
       " ('?', 14511),\n",
       " ('the', 10472),\n",
       " ('i', 10013),\n",
       " (',', 9489),\n",
       " ('!', 8807),\n",
       " ('you', 7493),\n",
       " ('a', 6860),\n",
       " (\"'\", 5555),\n",
       " ('it', 5524)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(enwords).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('。', 44900),\n",
       " ('我', 15087),\n",
       " ('？', 14454),\n",
       " ('你', 9087),\n",
       " ('！', 8915),\n",
       " ('了', 8663),\n",
       " ('的', 8053),\n",
       " ('，', 7291),\n",
       " ('一', 6091),\n",
       " ('是', 5946)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(chwords).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21739, 4054)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(enwords)),len(set(chwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ch2ind = {}\n",
    "ind2ch = {}\n",
    "en2ind = {}\n",
    "ind2en = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "specialchars = ['<eos>','<start>','<end>','<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addchar(what2ind,ind2what,char):\n",
    "    if char in what2ind:\n",
    "        return \n",
    "    ind2what[len(what2ind)] = char\n",
    "    what2ind[char] = len(what2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for one in specialchars:\n",
    "    addchar(ch2ind,ind2ch,one)\n",
    "    addchar(en2ind,ind2en,one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word,_ in Counter(enwords).most_common(10000):\n",
    "    addchar(en2ind,ind2en,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for word,_ in Counter(chwords).most_common(10000):\n",
    "    addchar(ch2ind,ind2ch,word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10004, 4058)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en2ind),len(ch2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_x_in = []\n",
    "dat_y_in = []\n",
    "dat_y_out = []\n",
    "\n",
    "dat_x_len = []\n",
    "dat_y_len = []\n",
    "\n",
    "for ensent in enlines:\n",
    "    indsent = [en2ind.get(i,en2ind['<unk>']) for i in ensent]\n",
    "    indsent.append(en2ind['<eos>'])\n",
    "    dat_x_in.append(indsent)\n",
    "    dat_x_len.append(len(indsent))\n",
    "    \n",
    "for chsent in chlines:\n",
    "    indsent = [ch2ind.get(i,ch2ind['<unk>']) for i in chsent]\n",
    "    #indsent.append(ch2ind['<eos>'])\n",
    "    dat_y_in.append([ch2ind['<start>']] + indsent)\n",
    "    dat_y_out.append(indsent + [ch2ind['<end>']])\n",
    "    dat_y_len.append(len(indsent) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['couple', '.', '<eos>']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ind2en[i] for i in dat_x_in[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start>', '一', '对', '夫', '妻', '。']"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ind2ch[i] for i in dat_y_in[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一', '对', '夫', '妻', '。', '<end>']"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ind2ch[i] for i in dat_y_out[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 6)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_x_len[4],dat_y_len[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103912, 103912, 103912, 103912, 103912)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dat_x_in),\\\n",
    "len(dat_y_in),\\\n",
    "len(dat_y_out),\\\n",
    "len(dat_x_len),\\\n",
    "len(dat_y_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.layers import core as layers_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto(log_device_placement=True,allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "num_units = 512\n",
    "batch_size = 128\n",
    "layer_number = 2\n",
    "max_grad = 1.0\n",
    "dropout = 0.2\n",
    "src_vocab_size = len(en2ind)\n",
    "target_vocat_size = len(ch2ind)\n",
    "seq_max_len = sentlength + 1\n",
    "maximum_iterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "tf.reset_default_graph()\n",
    "config = tf.ConfigProto(log_device_placement=True,allow_soft_placement = True)\n",
    "config.gpu_options.allow_growth = True\n",
    "#config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "with tf.device('/gpu:1'):\n",
    "    initializer = tf.random_uniform_initializer(\n",
    "        -0.08, 0.08)\n",
    "    tf.get_variable_scope().set_initializer(initializer)\n",
    "    \n",
    "    x = tf.placeholder(\"int32\", [None, None])\n",
    "    y = tf.placeholder(\"int32\", [None, None])\n",
    "    y_in = tf.placeholder(\"int32\",[None,None])\n",
    "    \n",
    "    x_len = tf.placeholder(\"int32\",[None])\n",
    "    y_len = tf.placeholder(\"int32\",[None])\n",
    "    learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "    \n",
    "    # embedding\n",
    "    embedding_encoder = tf.get_variable(\n",
    "        \"embedding_encoder\", [src_vocab_size, embedding_size],dtype=tf.float32)\n",
    "    embedding_decoder = tf.get_variable(\n",
    "        \"embedding_decoder\", [target_vocat_size, embedding_size],dtype=tf.float32)\n",
    "    \n",
    "    encoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_encoder, x)\n",
    "    decoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_decoder, y_in)\n",
    "    \n",
    "    # encoder\n",
    "    num_bi_layers = int(layer_number / 2)\n",
    "    \n",
    "    # Build RNN cell\n",
    "    encoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "\n",
    "    # Run Dynamic RNN\n",
    "    #   encoder_outputs: [max_time, batch_size, num_units]\n",
    "    #   encoder_state: [batch_size, num_units]\n",
    "    encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "        encoder_cell, encoder_emb_inp,\n",
    "        sequence_length=x_len, time_major=False,dtype=tf.float32)\n",
    "        \n",
    "    \n",
    "    \n",
    "    batch_size_in = tf.shape(x)[0]\n",
    "    projection_layer = layers_core.Dense(\n",
    "        len(ch2ind), use_bias=False)\n",
    "    # Dynamic decoding\n",
    "    with tf.variable_scope(\"decode_layer\"):\n",
    "        # Build RNN cell\n",
    "        decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(num_units)\n",
    "        # Helper\n",
    "        helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "            decoder_emb_inp, y_len, time_major=False)\n",
    "        # Decoder\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, encoder_state,\n",
    "            output_layer=projection_layer)\n",
    "        # Dynamic decoding\n",
    "        outputs, _ , __ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "        logits = outputs.rnn_output\n",
    "        target_weights = tf.sequence_mask(\n",
    "            y_len, seq_max_len, dtype=logits.dtype)\n",
    "    \n",
    "    # predicting\n",
    "    # Helper\n",
    "    with tf.variable_scope(\"decode_layer\", reuse=True):\n",
    "        # Helper\n",
    "        helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "            embedding_decoder,\n",
    "            tf.fill([batch_size_in], ch2ind['<start>']), ch2ind['<end>'])\n",
    "\n",
    "        # Decoder\n",
    "        decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "            decoder_cell, helper, encoder_state,\n",
    "            output_layer=projection_layer)\n",
    "        # Dynamic decoding\n",
    "        outputs, _ , __= tf.contrib.seq2seq.dynamic_decode(\n",
    "            decoder, maximum_iterations=maximum_iterations)\n",
    "        translations = outputs.sample_id\n",
    "        \n",
    "\n",
    "    # calculate loss\n",
    "    crossent = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=y, logits=logits)\n",
    "    train_loss = (tf.reduce_sum(crossent * target_weights) /\n",
    "        tf.cast(batch_size_in,tf.float32))\n",
    "    \n",
    "    optimizer_ori = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    trainable_params = tf.trainable_variables()\n",
    "    gradients = tf.gradients(train_loss, trainable_params)\n",
    "    clip_gradients, _ = tf.clip_by_global_norm(gradients, max_grad)\n",
    "    global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    optimizer = optimizer_ori.apply_gradients(\n",
    "            zip(clip_gradients, trainable_params), global_step=global_step)\n",
    "    #optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(train_loss)\n",
    "    #trainop = tflearn.TrainOp(loss=train_loss, optimizer=optimizer,\n",
    "    #                          metric=train_loss, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6, 512)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.run(encoder_emb_inp,feed_dict={\n",
    "    x:np.asarray(dat_x_in[:1])\n",
    "}).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dat_x_in = tf.keras.preprocessing.sequence.pad_sequences(dat_x_in,padding='post',value=en2ind['<eos>'])\n",
    "dat_y_in = tf.keras.preprocessing.sequence.pad_sequences(dat_y_in,padding='post',value=en2ind['<end>'])\n",
    "dat_y_out = tf.keras.preprocessing.sequence.pad_sequences(dat_y_out,padding='post',value=en2ind['<end>'])\n",
    "\n",
    "dat_x_len = np.asarray(dat_x_len)\n",
    "dat_y_len = np.asarray(dat_y_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((103912, 6), (103912, 6), (103912, 6), (103912,), (103912,))"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_x_in.shape,dat_y_in.shape,dat_y_out.shape,dat_x_len.shape,dat_y_len.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 40 batch 810 lr 7.62939453125e-06 loss 0.38680240511894226 99.90 % [=================================================>-] 103808/103912 \t used:17s eta:0 s"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "beginning_lr = 4\n",
    "for one_epoch in range(0,40):\n",
    "    index = np.asarray(list(range(len(dat_x_in))))\n",
    "    np.random.shuffle(index)\n",
    "    pb = ProgressBar(worksum=len(index))\n",
    "    pb.startjob()\n",
    "    for i in range(0,len(index),batch_size):\n",
    "        batchindex = index[i:i + batch_size]\n",
    "        \n",
    "        batch_lr = beginning_lr if one_epoch < 20 else beginning_lr * 0.5 ** (one_epoch - 20)\n",
    "        if len(batchindex) < batch_size:\n",
    "            break\n",
    "        _,batch_loss = session.run([optimizer,train_loss],feed_dict={\n",
    "            x:dat_x_in[batchindex],\n",
    "            y:dat_y_out[batchindex],\n",
    "            y_in:dat_y_in[batchindex],\n",
    "\n",
    "            x_len:dat_x_len[batchindex],\n",
    "            y_len:dat_y_len[batchindex],\n",
    "            learning_rate:batch_lr,\n",
    "        })\n",
    "        pb.info = \"EPOCH {} batch {} lr {} loss {}\".format(one_epoch + 1,i // batch_size,batch_lr,batch_loss)\n",
    "        pb.complete(batch_size)\n",
    "        losses.append(batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f5347d106d8>"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxGJCAW6iEhEKNBFRCJCgS4iEhH/H6MO7fRzJu4BAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5347d06a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pd.DataFrame(losses).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(sent):\n",
    "    senttoken = [en2ind[i.lower()] for i in sent.split()]\n",
    "    senttoken.append(en2ind['<eos>'])\n",
    "    inputx = np.asarray([senttoken])\n",
    "    inputx_len = np.asarray([len(senttoken)])\n",
    "    print(inputx,inputx_len)\n",
    "    batch_translations = session.run(translations,feed_dict={\n",
    "            x:inputx,\n",
    "            x_len:inputx_len,\n",
    "        })[0]\n",
    "    return ''.join([ind2ch[i] for i in batch_translations])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_sentence = \"i love shopping .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   7   84 1249    4    0]] [5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'我爱购物。<end>'"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(source_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! mkdir models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/seq2seq_model'"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(session,'models/seq2seq_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 meta meta 53903364  7月  5 20:45 models/seq2seq_model.data-00000-of-00001\r\n"
     ]
    }
   ],
   "source": [
    "! ls -l 'models/seq2seq_model.data-00000-of-00001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1.3_python",
   "language": "python",
   "name": "tf1.3_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
